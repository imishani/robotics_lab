{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rsAruco.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import threading\n",
    "import time\n",
    "# import rsAruco as ar\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2.aruco as aruco\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "# print(aruco_dict)\n",
    "# # second parameter is id number\n",
    "# # last parameter is total image size\n",
    "# img = aruco.drawMarker(aruco_dict, 1, 100)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "center=np.array([1, 2, 3], dtype='float64')\n",
    "# color_image = np.array([1])\n",
    "\n",
    "class cameraDetection (threading.Thread):\n",
    "    def __init__(self, threadID, name):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.__flag = threading.Event()     # 用于暂停线程的标识\n",
    "        self.__flag.set()       # 设置为True\n",
    "        self.__running = threading.Event()      # 用于停止线程的标识\n",
    "        self.__running.set()      # 将running设置为True\n",
    "    def run(self):\n",
    "        pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "        # Start streaming\n",
    "        print(\"Start streaming\")\n",
    "        pipeline.start(config)\n",
    "        ##########################\n",
    "#         stream = pipeline.get_stream(rs.stream.depth)\n",
    "#         intrinsics = stream.get_intrinsics()\n",
    "        ##########################\n",
    "        \n",
    "   \n",
    "        while cv2.waitKey(1)<0 and self.__running.isSet():\n",
    "            global color_image\n",
    "#             global color_image\n",
    "            self.__flag.wait()      # 为True时立即返回, 为False时阻塞直到内部的标识位为True后返回\n",
    "            # Wait for a coherent pair of frames: depth and color\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            color_frame = frames.get_color_frame()\n",
    "            \n",
    "            # get intrinsic of color image\n",
    "            color_intrinsics = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "            \n",
    "            # Convert images to numpy arrays\n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "#             print(depth_image.shape)\n",
    "#             print(color_image.shape)\n",
    "            # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            # Stack both images horizontally\n",
    "#             images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "            # Show images\n",
    "        #         cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        #         cv2.imshow(\"RealSense\", images)\n",
    "        #         plt.figure(1)\n",
    "        #         plt.subplot(121)\n",
    "        #         plt.imshow(color_image)\n",
    "        #         plt.subplot(122)\n",
    "        #         plt.imshow(depth_image)\n",
    "        #         cv2.waitKey(1)\n",
    "\n",
    "            # Our operations on the frame come here\n",
    "            gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "            aruco_dict = aruco.Dictionary_get(aruco.DICT_ARUCO_ORIGINAL)\n",
    "            parameters =  aruco.DetectorParameters_create()\n",
    "\n",
    "            #lists of ids and the corners beloning to each id\n",
    "            corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "        #         print(corners)\n",
    "            if len(corners)!=0:\n",
    "                point = np.average(corners[0][0], axis=0)\n",
    "                depth = depth_frame.get_distance(point[0], point[1])\n",
    "                point = np.append(point,depth)\n",
    "                if depth!=0:\n",
    "                    global center\n",
    "#                     print(\"center:%f %f, depth:%f m\" %(point[0], point[1], point[2]))\n",
    "                    x=point[0]\n",
    "                    y=point[1]\n",
    "                    z=point[2]\n",
    "                    ## see rs2 document: \n",
    "                    ## https://github.com/IntelRealSense/librealsense/wiki/Projection-in-RealSense-SDK-2.0#point-coordinates\n",
    "                    ## and example: https://github.com/IntelRealSense/librealsense/wiki/Projection-in-RealSense-SDK-2.0#point-coordinates\n",
    "                    x,y,z=rs.rs2_deproject_pixel_to_point(color_intrinsics, [x, y], z)\n",
    "                    center=[x,y,z]\n",
    "#                     print(center)\n",
    "                    color_image = aruco.drawDetectedMarkers(color_image, corners)\n",
    "                    \n",
    "#                     cv2.imwrite('./color.jpg',color_image)\n",
    "\n",
    "            #print(rejectedImgPoints)\n",
    "            # Display the resulting frame\n",
    "#             print(\"about to show!\")\n",
    "#             cv2.startWindowThread()\n",
    "        ## if uncommented, crash!!!\n",
    "#             cv2.namedWindow('Detection', cv2.WINDOW_AUTOSIZE)\n",
    "#             cv2.imshow(\"Detection\", color_image)\n",
    "#             cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        # Stop streaming\n",
    "        cv2.destroyAllWindows()\n",
    "        pipeline.stop()\n",
    "        time.sleep(1)\n",
    "    def pause(self):\n",
    "        self.__flag.clear()     # 设置为False, 让线程阻塞\n",
    "\n",
    "    def resume(self):\n",
    "        self.__flag.set()    # 设置为True, 让线程停止阻塞\n",
    "\n",
    "    def stop(self):\n",
    "        self.__flag.set()       # 将线程从暂停状态恢复, 如何已经暂停的话\n",
    "        self.__running.clear()        # 设置为False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    thread = cameraDetection(1, \"rsArucoDetection\")\n",
    "    thread.start()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
